# Copyright 2026 Telef√≥nica Soluciones de Inform√°tica y Comunicaciones de Espa√±a, S.A.U.
#
# This file is part of kafnus
#
# kafnus is free software: you can redistribute it and/or
# modify it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# kafnus is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero
# General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with kafnus. If not, see http://www.gnu.org/licenses/.

import os
import time
import json
from datetime import datetime, timedelta
from confluent_kafka import Consumer

from common.common_test import OrionRequestData, ServiceOperations
from common.config import logger

DEFAULT_NOTIF_COUNT = 1000
SENTINEL_ID = "__END__"
RAW_TOPIC = "smc_raw_historic"
PROCESSED_TOPIC = "smc_test_historic_processed"


def test_ngsi_consumer_backlog(multiservice_stack):
    """
    Stress consumer queue of kafnus-ngsi:
    - Stop kafnus-ngsi
    - Generates N notifications (backlog) in RAW topic
    - Send a sentinel signal
    - Start kafnus-ngsi
    - Check all is processed when sentinel is in PROCESSED topic
    """

    notif_count = int(os.getenv("NGSI_BACKLOG_NOTIF_COUNT", DEFAULT_NOTIF_COUNT))

    compose = multiservice_stack.compose
    logger.info(f"üß™ Starting NGSI consumer backlog test: N={notif_count}")

    # 1) Stops kafnus-ngsi to acumulate in backlog
    logger.info("‚è∏ Stopping kafnus-ngsi to build backlog")
    compose.safe_stop("kafnus-ngsi")

    start_ts = datetime.utcnow()

    # Subscription to Kafka RAW (which consumes kafnus-ngsi)
    subscriptions = {
        "historic": {
            "description": f"Test:HISTORIC:ngsi_backlog_{notif_count}",
            "status": "active",
            "subject": {
                "entities": [{"idPattern": ".*", "type": "Test"}],
                "condition": {"attrs": ["TimeInstant"]}  # force notification in each update
            },
            "notification": {
                "kafkaCustom": {
                    "url": "kafka://kafka:29092",
                    "topic": RAW_TOPIC
                },
                # adds a counter to allow check it
                "attrs": ["TimeInstant", "temperature", "seq"]
            }
        }
    }

    # 2) Send N updates which generates N RAW notifications 
    #    (all similar, only changes TimeInstant/seq)
    updates = []
    for i in range(notif_count):
        ti = (start_ts + timedelta(milliseconds=i)).isoformat() + "Z"
        updates.append({
            "id": f"E{i}",
            "type": "Test",
            "TimeInstant": {"type": "DateTime", "value": ti},
            "temperature": {"type": "Float", "value": 1.0},
            "seq": {"type": "Integer", "value": i},
        })

    # 2a) Crate subscription and put into Orion backlog
    orion_request = OrionRequestData(
        name="ngsi_backlog_setup",
        service="test",
        subservice="/ngsi_backlog",
        subscriptions=subscriptions,
        updateEntities=updates,
    )
    ops = ServiceOperations(multiservice_stack, [orion_request])
    t_send0 = time.time()
    ops.orion_set_up()
    t_send = time.time() - t_send0
    logger.info(f"üì§ Sent {notif_count} updates (and backlog to RAW) in {t_send:.2f}s")

    # 2b) Send sentinel signal at the end (same subscription -> also to RAW)
    sentinel_req = OrionRequestData(
        name="ngsi_backlog_sentinel",
        service="test",
        subservice="/ngsi_backlog_sentinel",
        subscriptions={},  # no recreate subs
        updateEntities=[{
            "id": SENTINEL_ID,
            "type": "Test",
            "TimeInstant": {"type": "DateTime", "value": datetime.utcnow().isoformat() + "Z"},
            "temperature": {"type": "Float", "value": -1.0},
            "seq": {"type": "Integer", "value": -1},
        }],
    )
    ops = ServiceOperations(multiservice_stack, [sentinel_req])
    ops.orion_set_up()

    # 3) Starts kafnus-ngsi and wait to process  backlog (sentinel in PROCESSED)
    logger.info("‚ñ∂ Starting kafnus-ngsi")
    compose.safe_start("kafnus-ngsi")

    t0 = time.time()
    ok = wait_for_ngsi_sentinel(
        kafka_bootstrap=f"{multiservice_stack.kafkaHost}:{multiservice_stack.kafkaPort}",
        sentinel_id=SENTINEL_ID,
        topic=PROCESSED_TOPIC,
        timeout=max(90, min(600, notif_count // 5)),
    )
    t_drain = time.time() - t0

    assert ok, "‚ùå kafnus-ngsi did not process backlog up to sentinel"
    logger.info(f"‚úÖ NGSI drained backlog up to sentinel in {t_drain:.2f}s")


def wait_for_ngsi_sentinel(kafka_bootstrap, sentinel_id, topic, timeout=60):
    consumer = Consumer({
        "bootstrap.servers": kafka_bootstrap,
        "group.id": f"ngsi-sentinel-{int(time.time())}",
        "auto.offset.reset": "earliest",
    })

    consumer.subscribe([topic])
    start = time.time()

    try:
        while time.time() - start < timeout:
            msg = consumer.poll(2.0)
            if msg is None or msg.error():
                continue

            payload = json.loads(msg.value())
            entity_id = payload.get("entityid") or payload.get("payload", {}).get("entityid")

            if entity_id == sentinel_id:
                logger.info("‚úÖ NGSI sentinel processed")
                return True
    finally:
        consumer.close()

    return False
