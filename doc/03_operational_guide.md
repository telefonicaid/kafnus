# ‚öôÔ∏è Operational Guide

This document describes the information needed for running and maintaining a Kafnus deployment: starting, stopping, health checks, logs, connector management, and troubleshooting.

---

## ‚ñ∂Ô∏è 1. Starting & Stopping

### 1.1 Start Services

From the project‚Äôs `docker/` directory:

```bash
cd docker/
./docker-up.sh
```

‚Äì If using an external PostGIS, comment out its compose line in `docker-up.sh`.  
‚Äì Ensure the `kafka-postgis-net` network exists (see installation).

### 1.2 Stop Services

```bash
cd docker/
./docker-down.sh
```

This stops all containers and removes volumes & orphaned networks.

---

## üõ°Ô∏è 2. Health Checks

### 2.1 Container Status

```bash
docker ps
```

Confirm these are **Up (healthy)**:

```plaintext
kafka           ‚Üê Kafka broker
kafnus-connect  ‚Üê Kafnus Connect
kafnus-ngsi     ‚Üê Kafnus NGSI (Node.js)
orion           ‚Üê Context Broker
mongo           ‚Üê MongoDB
iot-postgis     ‚Üê PostGIS (if internal)
```

### 2.2 Check Connector Health

List connectors and ensure tasks are running:

```bash
curl -s http://localhost:8083/connectors | jq .
```

For each connector:

```bash
curl -s http://localhost:8083/connectors/<name>/status | jq .
```

---

## üîç 3. Logs & Diagnostics

Still in progress...

### 3.1 View Container Logs

Tail logs for quick debugging:

```bash
docker logs -f kafnus-connect
docker logs -f kafnus-ngsi
docker logs -f iot-postgis
```

### 3.2 Kafnus Connect Errors

‚Äì Failed connector loads appear in `kafnus-connect` logs.  
‚Äì DLQ errors land in the topic `raw_errors`. To inspect:

```bash
docker exec -it kafka \
  /opt/kafka/bin/kafka-console-consumer.sh \
    --bootstrap-server kafka:9092 \
    --topic raw_errors \
    --from-beginning \
    --max-messages 10
```

---

## üîÑ 4. Connector Management

### 4.1 Register a Connector

From project root `sinks/`:

```bash
cd sinks/
curl -X POST -H "Content-Type: application/json" \
     --data @pg-sink-historic.json \
     http://localhost:8083/connectors
```

Repeat for `pg-sink-lastdata.json`, `pg-sink-mutable.json`, `pg-sink-errors.json`, `mdb-sink.json` and `http-sink.json`.

### 4.2 Update Connector Config

Use HTTP PUT to update a running connector:

```bash
curl -X PUT -H "Content-Type: application/json" \
     --data @my-updated-config.json \
     http://localhost:8083/connectors/<name>/config
```

### 4.3 Delete a Connector

```bash
curl -X DELETE http://localhost:8083/connectors/<name>
```

### 4.4 Multi-Tenant / Multi-Client Usage

The provided sink configurations (`pg-sink-historic.json`, `pg-sink-lastdata.json`, `pg-sink-mutable.json`,  
`pg-sink-errors.json`, `mdb-sink.json` and `http-sink.json`) as well as the example test scenarios under  
`/tests_end2end/functional/cases` are **designed to work with a single tenant (fiware-service) named `test`**.

If you want to onboard additional clients (e.g. `smartcity1`, `smartcity2`), you need to create a **separate set of sinks** for each tenant. This usually involves:

- Copying the base sink configuration JSON files
- Replacing the `config.topic` prefixes (each tenant uses isolated Kafka topics)
- Replacing the `config.table.name.format` prefixes (so each tenant persists to its own DB schemas/tables)
- Reviewing DB connection options if different PostGIS/Mongo instances are used (check for `config.connection.url`)

Once adapted, register the new connector set using the same process (`curl -X POST ...`).

> üí° Example: You would typically have one set of sinks (`pg-sink-historic`, `pg-sink-lastdata`, `pg-sink-mutable`,  
> `pg-sink-errors`...) for **`smartcity1`**, and another equivalent set for **`smartcity2`**.  
> Each set handles only its own tenant‚Äôs traffic.

### 4.5 Regex Topics Caveat for Mongo Sink

The MongoDB sink connector can be configured either with a **static list of topics** (`topics`) or with a **regular expression** (`topics.regex`).  

‚ö†Ô∏è **Important:**  
You cannot configure both `topics` and `topics.regex` at the same time ‚Äî the connector will fail to start if both are present.  

When using `topics.regex`, the matching is performed **only once at startup**.  
Any topics created later that match the regex will **not** be processed automatically.

To make the connector start consuming new topics, you must either:

1. **Redeploy the connector**, or  
2. **Update its configuration** via a `PUT` to the connector‚Äôs `/config` endpoint (this effectively refreshes the regex evaluation).  

Example update command:

```bash
curl -X PUT -H "Content-Type: application/json" \
     --data @mdb-sink.json \
     http://localhost:8083/connectors/mongo-sink/config
```

‚ö†Ô∏è **Operational Note:**  
This needs to be clearly documented as part of the onboarding process for new tenants/services.  

- For **PostGIS**, the current approach is to spin up one connector per service.  
- For **MongoDB**, two alternatives exist:  
  - adopt the same per-service connector strategy, or  
  - require a connector update (via `PUT`) whenever a new topic needs to be consumed.

---

## üìä 5. Topic & Data Verification

### 5.1 Inspect Topics

List topics:

```bash
docker exec kafka kafka-topics --list --bootstrap-server kafka:9092
```

Consume a sample:

```bash
docker exec kafka \
  /opt/kafka/bin/kafka-console-consumer.sh \
    --bootstrap-server kafka:9092 \
    --topic <topic-name> \
    --from-beginning \
    --max-messages 5
```

### 5.2 Verify DB Inserts

Connect to PostGIS:

```bash
docker exec -it iot-postgis psql -U postgres -d tests
```

Run SQL:

```sql
SELECT * FROM test.simple_sensor LIMIT 5;
```

---

## ‚ö†Ô∏è 6. Common Issues & Fixes

- **Connector won't start**  
  Check plugins are available in `kafnus-connect`.  
- **Port conflicts**  
  Ensure no other service is using ports 9092, 8083, 1026, 1883, 5432, 27017.  
- **Network not found**  
  Create `kafka-postgis-net`:  
  ```bash
  docker network create kafka-postgis-net
  ```  
- **JMX agent mount fails**  
  Ensure `kafnus-connect/monitoring/jmx_prometheus_javaagent.jar` is a file, not directory, and path has no spaces.

---

## üß≠ Navigation

- [‚¨ÖÔ∏è Previous: Architecture](/doc//02_architecture.md)
- [üè† Main index](../README.md#documentation)
- [‚û°Ô∏è Next: Docker Details](/doc//04_docker.md)

